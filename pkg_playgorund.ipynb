{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import db_train_utils.db_train_utils as db_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parms_path = '/home/dsi/toozig/gonen-lab/users/toozig/projects/deepBind_pipeline/deepBind_run/models/IB_models/THC_0307.Rep-MICHELLE_0314_v2_version_2.0/THC_0307.Rep-MICHELLE_0314_v2_version_2.0_parameters.csv'\n",
    "parms_train_path = '/home/dsi/toozig/gonen-lab/users/toozig/projects/deepBind_pipeline/deepBind_run/models/IB_models/THC_0307.Rep-MICHELLE_0314_v2_version_2.0/THC_0307.Rep-MICHELLE_0314_v2_version_2.0_train_parameters.csv'\n",
    "chip_seq_path = '/home/dsi/toozig/orenstein_lab/train/CHS/PRDM5/THC_0307.Rep-MICHELLE_0314.peaks'\n",
    "version = 'v2'\n",
    "prefix = 'debug'\n",
    "protein = chip_seq_path.split('/')[-2]\n",
    "cite = chip_seq_path.split('/')[-1].split('.pe')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = 'Homo Sapiens'\n",
    "experiment ='chip seq'\n",
    "lab = 'ibis_2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 06:21:59.277296: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-01 06:21:59.510947: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-01 06:22:00.301732: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-01 06:22:00.301789: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-01 06:22:00.477907: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-01 06:22:00.915849: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-01 06:22:00.920080: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-01 06:22:05.466377: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed path: /tmp/toozig/THC_0307_centered.bed\n",
      "positive data: /tmp/toozig/THC_0307_centered.fa\n",
      "negative data: /tmp/toozig/THC_0307_centered._negative.fa\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from db_train_utils.train_chip_seq.chip_seq_main import run_chip_seq\n",
    "from db_train_utils.train_chip_seq.chip_seq_utils import get_db_chs_object\n",
    "from db_train_utils.train_chip_seq.ibis_chip_seq_main import run_ibis_chip_seq\n",
    "import ibis_utils.ibis_utils as iu\n",
    "from Bio import SeqIO\n",
    "\n",
    "TMP_DIR = '/tmp/toozig/'\n",
    "\n",
    "\n",
    "def get_input_shape(fasta_path):\n",
    "    # read one sequence to get the shape\n",
    "    fasta_sequences = SeqIO.parse(open(fasta_path), 'fasta')\n",
    "    seq = next(fasta_sequences)\n",
    "    return len(seq.seq), 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "name_col = 'name'\n",
    "center_col = 'abs_summit'\n",
    "centered_bed = iu.get_centered_bed(chip_seq_path, TMP_DIR,center_col , name_col)\n",
    "positive_data = iu.get_fasta_from_bed(centered_bed, TMP_DIR, genome='hg38')\n",
    "negative_data = iu.negative_shuffle(positive_data)\n",
    "print(f'bed path: {centered_bed}\\npositive data: {positive_data}\\nnegative data: {negative_data}')\n",
    "\n",
    "input_shape = get_input_shape(positive_data)\n",
    "# print(f'bed path: {centered_bed}\\npositive data: {positive_data}\\nnegative data: {negative_data}')\n",
    "db_chs_obj = get_db_chs_object(protein, species, experiment, lab, cite, input_shape)\n",
    "# # print('running chip seq')\n",
    "# # run_ibis_chip_seq(positive_data, negative_data, n_exp, commetAPIKey, db_chs_obj, version)\n",
    "# print(positive_data)\n",
    "# centered_bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/dsi/toozig/gonen-lab/users/toozig/projects/deepBind_pipeline/deepBind_run/models/IB_models/THC_0307.Rep-MICHELLE_0314_v2_version_2.0/THC_0307.Rep-MICHELLE_0314_v2_version_2.0_train_parameters.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m configuration_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparms_train_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation.pearson_correlation\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m configuration_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m row \u001b[38;5;241m=\u001b[39m configuration_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/deepBindEnv/lib64/python3.9/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/deepBindEnv/lib64/python3.9/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.virtualenvs/deepBindEnv/lib64/python3.9/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/deepBindEnv/lib64/python3.9/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.virtualenvs/deepBindEnv/lib64/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/dsi/toozig/gonen-lab/users/toozig/projects/deepBind_pipeline/deepBind_run/models/IB_models/THC_0307.Rep-MICHELLE_0314_v2_version_2.0/THC_0307.Rep-MICHELLE_0314_v2_version_2.0_train_parameters.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "configuration_df = pd.read_csv(parms_train_path).sort_values('validation.pearson_correlation', ascending=False)\n",
    "configuration_df.head(2)\n",
    "row = configuration_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_train_utils.train_chip_seq.chip_seq_utils import   prepare_chs_train_test, process_init_result, prepare_chs_ibis_df, get_train_test_data\n",
    "from db_train_utils.train_chip_seq.chip_seq_main import *\n",
    "from db_train_utils.train_global_args import *\n",
    "from db_train_utils.train_global_function import *\n",
    "import concurrent.futures\n",
    "from keras.saving import register_keras_serializable\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from tqdm import tqdm\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "POSITIVE_DATA = TRAIN_SET\n",
    "NEGATIVE_DATA = TEST_SET\n",
    "\n",
    "TMP_DIR = '/tmp/toozig/'\n",
    "\n",
    "@register_keras_serializable()\n",
    "def __tf_pearson_correlation(y_true, y_pred): \n",
    "    # use smoothing for not resulting in NaN values\n",
    "    # pearson correlation coefficient\n",
    "    # https://github.com/WenYanger/Keras_Metrics\n",
    "    epsilon = 10e-5\n",
    "    x = y_true\n",
    "    y = y_pred\n",
    "    mx = K.mean(x)\n",
    "    my = K.mean(y)\n",
    "    xm, ym = x - mx, y - my\n",
    "    r_num = K.sum(xm * ym)\n",
    "    x_square_sum = K.sum(xm * xm)\n",
    "    y_square_sum = K.sum(ym * ym)\n",
    "    r_den = K.sqrt(x_square_sum * y_square_sum)\n",
    "    r = r_num / (r_den + epsilon)\n",
    "    return K.mean(r)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_model2(n_motif, length_motif, dropout_rate,\n",
    "                learning_rate, hidden_layer, l1=0.0, l2=0.0,\n",
    "                binary=False, **kwargs):\n",
    "    # Define the regularizer\n",
    "    kernel_regularizer = regularizers.l1_l2(l1=l1, l2=l2)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=n_motif,\n",
    "                     kernel_size=(length_motif,),\n",
    "                     strides=STRIDES,\n",
    "                     activation='relu',\n",
    "                     input_shape=(None, 4),\n",
    "                     kernel_regularizer=kernel_regularizer  # Add kernel regularizer\n",
    "                     )\n",
    "              )\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "    if hidden_layer:\n",
    "        model.add(Dense(units=32,\n",
    "                        activation='relu',\n",
    "                        ))\n",
    "\n",
    "    model.add(Dense(units=1,\n",
    "                    activation='sigmoid' if binary else 'linear',\n",
    "                    )) \n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=BinaryCrossentropy() if binary else MSE,\n",
    "                   metrics=[__tf_pearson_correlation])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_fcn_model(n_motif, length_motif, dropout_rate, learning_rate, hidden_layer,\n",
    "                        dense_output, lstm_output, dense2_output ,binary=False, **kwargs):\n",
    "    # Create a Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add a Conv1D layer\n",
    "    model.add(Conv1D(filters=n_motif,\n",
    "                     kernel_size=(length_motif,),\n",
    "                     strides=STRIDES,\n",
    "                     activation='relu',\n",
    "                     input_shape=(None, 4),  # None indicates that any input length is acceptable\n",
    "                     ))\n",
    "\n",
    "    # Add a MaxPooling1D layer\n",
    "    model.add(MaxPooling1D(pool_size=(length_motif -  1,)))\n",
    "\n",
    "    # Add a Dropout layer\n",
    "    model.add(Dropout(rate=dropout_rate))\n",
    "\n",
    "    # Add a TimeDistributed layer\n",
    "    model.add(TimeDistributed(Dense(dense_output, activation='relu')))\n",
    "\n",
    "    # Add an LSTM layer\n",
    "    model.add(LSTM(lstm_output))\n",
    "\n",
    "    if hidden_layer:\n",
    "        model.add(Dense(units=32,\n",
    "                        activation=RELU,\n",
    "                        ))\n",
    "    # Add a Dense layer\n",
    "    model.add(Dense(units=1,\n",
    "                    activation= SIGMOID if binary else LINEAR,\n",
    "                    )) \n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss= BinaryCrossentropy() if binary else MSE,\n",
    "                   metrics=[__tf_pearson_correlation])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "VERSION_DICT = {'v1': build_fcn_model,\n",
    "                'v2': build_model2 }\n",
    "\n",
    "def train_ibis(parameter_dict, x_train, y_train, x_test, y_test, version='v1', final=False):\n",
    "    model = VERSION_DICT[version](**parameter_dict)\n",
    "    if final:\n",
    "        model, train_eval_dict = train_final_model(model, x_train, y_train, x_test, y_test, parameter_dict[LEARNING_STEP])\n",
    "    else:\n",
    "        model, train_eval_dict = train_model(model, x_train, y_train,\n",
    "                                        x_test, y_test, parameter_dict[LEARNING_STEP])\n",
    "    val_eval_dict = eval_model(model, x_train, y_train)\n",
    "    test_eval_dict = eval_model(model, x_test ,y_test)\n",
    "    val_dict = {TRAIN_STR: train_eval_dict, VAL_STR: val_eval_dict, TEST_STR: test_eval_dict}\n",
    "    return model, val_dict\n",
    "\n",
    "\n",
    "\n",
    "def run_ibis_single_expirement(row, to_split, x_train, y_train, version='v1'):\n",
    "    final = not to_split\n",
    "    print('running expirement', row[EXP_ID], 'model:', version)\n",
    "    # print(row)\n",
    "\n",
    "    x_train, y_train, x_test, y_test  = prepare_chs_train_test(x_train, y_train, to_split)\n",
    "    print('prepared data')\n",
    "    parameter_dict = row if isinstance(row, dict) else row.to_dict()\n",
    "    print('got parms')\n",
    "    model, train_eval_dict = train_ibis(parameter_dict, x_train, y_train, x_test, y_test, version, final)\n",
    "    print('finished running expirement')\n",
    "    if DEBUG:\n",
    "        print(f\"finished expirement {row.expirement_id}\")\n",
    "    if to_split:\n",
    "        model = None\n",
    "    return {EXP_ID: row[EXP_ID],'model': model, 'score_dict' :train_eval_dict}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62788, 200, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  db_train_utils.train_chip_seq.chip_seq_utils import   prepare_chs_train_test, process_init_result, prepare_chs_ibis_df, get_train_test_data\n",
    "x_train, y_train = get_train_test_data(positive_data, negative_data, False)\n",
    "# run_ibis_single_expirement(row, False, x_train, y_train, version='v2')\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split = True\n",
    "x_train1, y_train1, x_test1, y_test1 = prepare_chs_train_test(x_train, y_train, to_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53369, 200, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1963/1963 [==============================] - 3s 1ms/step - loss: 0.1221 - __tf_pearson_correlation: 3.8965e-04\n",
      "1963/1963 [==============================] - 3s 1ms/step - loss: 0.0607 - __tf_pearson_correlation: 4.6209e-04\n",
      "1963/1963 [==============================] - 3s 1ms/step - loss: 0.0441 - __tf_pearson_correlation: 5.0473e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<keras.src.engine.sequential.Sequential at 0x7f878442e880>,\n",
       " {'fold_0_pearson_corr': 0.000389649358112365,\n",
       "  'fold_0_MSE': 0.12213493883609772,\n",
       "  'fold_1_pearson_corr': 0.0004620855033863336,\n",
       "  'fold_1_MSE': 0.06070816144347191,\n",
       "  'fold_2_pearson_corr': 0.0005047256709076464,\n",
       "  'fold_2_MSE': 0.0441492423415184})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_dict = row if isinstance(row, dict) else row.to_dict()\n",
    "model = VERSION_DICT[version](**parameter_dict)\n",
    "# model.summary()\n",
    "train_model(model, x_train, y_train, x_train, y_train, parameter_dict[LEARNING_STEP])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepBindEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
